{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie_Review_Classification_Word_Embeddings.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaxManfred/deep-learning/blob/master/notebooks/Movie_Review_Classification_Word_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WAZxO9uYjcvc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "from keras import preprocessing\n",
        "\n",
        "from keras import Sequential\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Flatten\n",
        "\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6iqkeI9jj9Cc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# number of words to consider as features\n",
        "max_features = 100_000\n",
        "\n",
        "# max review length\n",
        "max_review_length = 1_000\n",
        "\n",
        "# the dimension of the embedding vector space\n",
        "embedding_dimentionality = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cJPu03z-kNEl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load IMDB data\n",
        "(training_samples, training_labels), (test_samples, test_labels) = imdb.load_data(num_words = max_features)\n",
        "print(training_samples.shape)\n",
        "print(test_samples.shape)\n",
        "print(training_samples[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JceoyXrNkw9x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# turn lists of integers (the reviews are collections of word integers) into 2D tensorsof shape (num_samples, max_review_length)\n",
        "training_samples = preprocessing.sequence.pad_sequences(training_samples, maxlen=max_review_length)\n",
        "# print(training_samples.shape)\n",
        "test_samples = preprocessing.sequence.pad_sequences(test_samples, maxlen=max_review_length)\n",
        "# print(test_samples.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fvgwK_VBltmt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create neural network\n",
        "neural_network = Sequential()\n",
        "# create the embedding layers to traing: it will work on \n",
        "# max_features words in total \n",
        "# distributed in reviews of maximum length max_review_length \n",
        "# and will output a tensor of shape (num_samples, max_review_length, embedding_dimentionality)\n",
        "# so taht each word will be represented by a vector of length embedding_dimentionality\n",
        "neural_network.add(Embedding(max_features, embedding_dimentionality, input_length = max_review_length))\n",
        "# this layer will flatten the 3D tensor of shape (num_samples, max_review_length, embedding_dimentionality)\n",
        "# into a 2D tensor of shape (num_samples, max_review_length * embedding_dimentionality)\n",
        "neural_network.add(Flatten())\n",
        "# the add processing layers\n",
        "neural_network.add(Dense(16, activation='relu'))\n",
        "neural_network.add(Dense(16, activation='relu'))\n",
        "neural_network.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SItd0OLvps_a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define optimization process\n",
        "neural_network.compile(\n",
        "    optimizer = RMSprop(lr = 0.001), \n",
        "    loss = 'binary_crossentropy', \n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yU2i9zJXpy36",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# show neural network architecture\n",
        "neural_network.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "841IVmQvqkEf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_history = neural_network.fit(training_samples, training_labels, epochs = 20, batch_size = 512, validation_split = 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EwzQzhM8u_N-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save model to localhost\n",
        "neural_network.save_weights('movie_review_word_embeddings.h5')\n",
        "files.download('movie_review_word_embeddings.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b4PR4tverY57",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history_dict = training_history.history\n",
        "print('History keys: ', history_dict.keys())\n",
        "print('\\n')\n",
        "\n",
        "# display loss using matplot lib\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(history_dict['acc']) + 1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label = 'Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label = 'Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# clear diagram\n",
        "plt.clf()\n",
        "print('\\n')\n",
        "\n",
        "# display accuracy using matplotlib\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gsNPNWVlrBLU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}